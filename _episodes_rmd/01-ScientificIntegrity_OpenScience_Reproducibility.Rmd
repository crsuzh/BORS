---
source: Rmd
title: "Scientific integrity, Open Science and reproducibility"
teaching: 60
exercises: 60-90
questions: 
  - "What is Scientific integrity and what is the link to Open Science and reproducibility?"
  - "What is Open Science and which aspects are important to me?"
  - "What is reproducibility and why should I care about it?"
  - 
objectives: 
  - "Understand about the connections between Scientific integrity, Open Science and reproducibility "
  - "Name the requirements on designing, carrying out and reporting of research projects such that scientific integrity is respected"
  - "Discrimate between so-called negative and positive results"
  - "List all/many of the dimensions of Open Science"
  - "Explain why and know where to preregister studies"
  - "Apply these concepts when reading about research"
keypoints:
  - "Scientific integrity, Open Science and reproducibility are connected. "
  - "All three themes are important for the trustworthiness of research results"
  - "The tools that will be taught in this course help to increase trustworthiness"
---

```{r, include=FALSE}
source("../bin/chunk-options.R")
knitr_fig_path("01-")
```


# 1. What is scientific integrity and what is the link to Open Science and reproducibility?
## Scientific/research integrity at the University of Zurich

Often when the term "Scientific integrity" comes up one would think about topics such as

- Misconduct/ fraud procedures  
[https://www.research.uzh.ch/de/procedures/integrity.html](https://www.research.uzh.ch/de/procedures/integrity.html)

- Ethical issues, especially regarding research on humans and on animals  
[https://www.uzh.ch/cmsssl/en/researchinnovation/ethics.html](https://www.uzh.ch/cmsssl/en/researchinnovation/ethics.html)

- Conflicts of interest  
[https://www.uzh.ch/prof/apps/interessenbindungen/client/](https://www.uzh.ch/prof/apps/interessenbindungen/client/)  

Note that conflicts of interest can also be the subject of studies: [https://doi.org/10.1186/s13643-020-01318-5](https://doi.org/10.1186/s13643-020-01318-5)

For each of these topics we have the University of Zurich links here, most other universities will also have corresponding regulations in place. But these topics are not the main interest of this course, we will instead **focus at the aspects of research integrity discussed below**.


## National and international guidance documents on research integrity

Several guidance documents exist, see three European examples here:

- Towards a Research Integrity Culture at Universities (LERU)  
[https://www.leru.org/publications/towards-a-research-integrity-culture-at-universities-from-recommendations-to-implementation](https://www.leru.org/publications/towards-a-research-integrity-culture-at-universities-from-recommendations-to-implementation)

- The European Code of Conduct for Research Integrity  
[https://allea.org/code-of-conduct/](https://allea.org/code-of-conduct/)

- Scientific Integrity at the Swiss Academies of Arts and Sciences  
[https://akademien-schweiz.ch/en/uber-uns/kommissionen-und-arbeitsgruppen/wissenschaftliche-integritat/](https://akademien-schweiz.ch/en/uber-uns/kommissionen-und-arbeitsgruppen/wissenschaftliche-integritat/)

&rArr; We will have a brief look at each of the documents and work on the Swiss document in more detail.


## LERU: Towards a research integrity culture at Universities

In a summary chapter the guidance document states what Universities should do to empower sound research:

**Improve the design and conduct of research:**  
  - statistics, **research design, methodology and analysis**
  - newest standards  
  - understanding limitations  
  - checklists to improve design  


**Improve the soundness of reporting**
  - **reporting guidelines**
  - **pre-registration**
  - publish all components of experimental design.
  - **Value negative results and replication studies**

 &rArr; The points in bold are topics of this course and directly related to reproducibility as we will see below and later.


## European code of conduct for research integrity 

The EU code states that **Good research practices** are based on fundamental principles of research integrity. 

- **Reliability** in ensuring the quality of research, reflected in the design, the methodology, the analysis and the use of resources.

- **Honesty** in developing, undertaking, reviewing, reporting and communicating research in a transparent, fair, full and unbiased way.

- **Respect** for colleagues, research participants, society, ecosystems, cultural heritage and the environment.

- **Accountability** for the research from idea to publication, for its management and organisation, for training, supervision and mentoring, and for its wider impacts.

&rArr; You will find these same main principles in the Swiss guidance document! Adhering to the principles of reliability, honesty and accountability requires, among other aspects, to work reproducibly and openly.


## The Swiss code of conduct for scientific integrity

The same principles occur in the Swiss document, here with a direct pointer to reproducibility:

> _“Reliability, honesty, respect, and accountability are the basic principles of scientific integrity. They underpin the independence and credibility of science and its disciplines as well as the accountability and **reproducibility** of research findings and their acceptance by society. As a system operating according to specific rules, science has a responsibility to create the structures and an environment that foster scientific integrity.”_


## Quiz on the Swiss code of conduct for scientific integrity

For these questions, please read or search the [Code](https://akademien-schweiz.ch/en/uber-uns/kommissionen-und-arbeitsgruppen/wissenschaftliche-integritat/) until page 26.
> ## Audience
> At which of the following groups of people is the code of conduct aimed at?
> - researchers at research performing institutions
> - educators at higher education institutions
> - administrative staff at research performing institutions
> - students at higher education institutions
>
{: .challenge}

> ## Solution
> 
> T researchers at research performing institutions  
> T educators at higher education institutions  
> F administrative staff at research performing institutions  
> T students at higher education institutions  
>
{: .solution}

> ## Reliability
> For reliability researchers need to use, e.g.,
> - appropriate study designs
> - the most current methods
> - simple analysis methods
> - transparent reporting
> - traceable materials and data
>
{: .challenge}

> ## Solution
> T appropriate study designs  
> F the most current methods  
> F simple analysis methods  
> T transparent reporting  
> T traceable materials and data  
>
{: .solution}

> ## Computer code
> The code does not mention reproducible code (in the sense of computer code) directly. Find an implicit location where the use of reproducible code is implied by the standards of Chapter 4. Copy the entire bullet point or just the relevant verb.
>
{: .challenge}

> ## Solution
> The Code states "Researchers should design, undertake, analyse, document, and publish their research with care and with an awareness of their responsibility to society, the environment, and nature." Using a scripting language for data analysis and providing the corresponding code hence caters to the "documenting" step.
>
{: .solution}


> ## Negative results
>  The non-publication of so-called negative results can be seen as a violation of scientific integrity.
Find the behavior in Chapter 5 of the Code which this can be related to.
>
{: .challenge}

> ## Solution
> The Code lists "omitting or withholding data and data sources" as a behavior wich is an examples of scientific misconduct.
>
{: .solution}


## Example

>## Publication of negative results
>
**Therapeutic fashion and publication bias: the case of anti-arrhythmic drugs in heart attack**
>
- In the 1970s, it was found that the local anaesthetic drug lignocaine (lidocaine) suppressed arrhythmias after heart attacks  
- That this **claim was wrong** was difficult to recognise from small clinical trials looking only at effects on arrhythmias, not outcomes that really matter, like deaths.  
- Large clinical trials in the late 1980s showed that the drugs actually increased mortality.  
- The results of Hampton and co-authors' **small but negative trial** regarding the anti-arrhythmic agent lorcainide  were not published because no journal was willing to do so at the time.  
- A cumulative meta-analysis of previous anti-arrhythmic trials would have helped **avoid tens of thousands of unnecessarily early deaths**, even more so if results like those of Hampton and co-authors would have been available.  
- With the words ‘publication bias’ in the title, the trial results could finally be published in the early 1990s:  
**Therapeutic fashion and publication bias: the case of anti-arrhythmic drugs in heart attack**
>
J Hampton [https://journals.sagepub.com/doi/10.1177/0141076815608562](https://journals.sagepub.com/doi/10.1177/0141076815608562)
>
**Bottom line**: This is a very impressive example of the consequences of non-publication of "negative" results. The authors themselves are not to blame, they have maintained their integrity as researchers. The example shows that the publication of all results is indeed a principle of research integrity in the sense of the integrity of the research record as a whole.
{: .testimonial}

&nbsp;

# 2. What is Open Science?
## Let´s play the game "Open up your research"
[https://www.openscience.uzh.ch/de/moreopenscience/game.html]()

> ## Dimensions of Open Science
>  Which decisions did Emma need to take in the game?
>
{: .challenge}

> ## Solution
> 1. Involve a librarian?
> 2. Write a data management plan?
> 3. Preregister her research plan?
> 4. Make her data FAIR?
> 5. Publish Open Access?
> 6. Publish data and/or code?
>
{: .solution}

## UNESCO recommendation on Open Science  

In 2021 UNESCO published their recommendations for Open Science. From their point of view Open Science is a tool helping to create a sustainable future. In the quote stressed here we see the link of Open Science to scientific integrity and also reproducibility:

> _“Building on the essential principles of academic freedom, research integrity and scientific excellence, **open science sets a new paradigm that integrates into the scientific enterprise practices for reproducibility, transparency, sharing and collaboration** resulting from the increased opening of scientific contents, tools and processes.”_

![]({{ page.root }}/fig/01-UNESCO.png)
Image credit: [UNESCO Recommendation on Open Science](https://unesdoc.unesco.org/ark:/48223/pf0000379949.locale=en), CC-BY-SA.

Optional: Read the full recommendation text at [https://en.unesco.org/science-sustainable-future/open-science/recommendation](https://en.unesco.org/science-sustainable-future/open-science/recommendation).


## Open Science made easy by the Open Science in Psychology/Social Science initiatives

The Open Science in Psychology/Social Science initiatives summarize and explain the practice of Open Science in seven steps: [https://osf.io/hktmf/](https://osf.io/hktmf/). Some of these steps were also part of Emma's decision process. Here we show an abbreviated version of the seven steps:

![]({{ page.root }}/fig/01stepspicture.png)

Image credit: Eva Furrer, unlicensed, abbreviated version of [https://osf.io/hktmf/](https://osf.io/hktmf/).

We will revisit the following steps in this lesson:
1. **Create OSF account** (use easy infrastructure for collaboration)
2. **Pregregister your own studies** 
4. **Open Data** 
5. **Reproducible Code**  
6. **Open Access (preprints)** 

## What is preregistration? 
The Open up your research game and the seven steps above refer to preregistration. But what is preregistration? The Texas sharp shooter cartoon shows an unregistered experiment. The shooter first shoots and then draws the bull´s eyes around his shots. He did not preregister where he wanted to shoot before shooting. 

![]({{ page.root }}/fig/01-TexasSharpShooter.png)

Image credit: [Illustration by Dirk-Jan Hoek](https://www.researchgate.net/publication/343145874_Threats_of_a_replication_crisis_in_empirical_computer_science/figures?lo=1), CC-BY.

When a researcher preregisters a study, the design and precise goal of the study are declared openly in advance: the bull´s eye is drawn.

>## Origins of preregistration: clinical trials
> A clinical trial is an experiment involving human volunteers for example in the development of a new drug. Registration of clinical trials, i.e. announcing that a trial will be conducted and what its goal is before any data are collected,  **has become a standard** since the late 1990s. It is considered a scientific, ethical and moral responsibility for all trials because:
>
- Informed decisions are difficult under **publication bias and selective reporting**, i.e. the non-publication negative results and the focus on publication of positive results which might not reflect the original goals. Publication bias and selective reporting result in a biased view of the situation.
- Describing clinical trials in progress simplifies identification of research gaps 
- The early identification of potential problems contributes to **improvements in the quality **
>
>&rArr; [The Declaration of Helsinki](https://www.wma.net/policies-post/wma-declaration-of-helsinki-ethical-principles-for-medical-research-involving-human-subjects/) requires since the late 1990s: "Every clinical trial must be registered [...]”
{: .callout}





>## Registries (non-exhaustive list)
>Here is a list of registries, where (pre)registration can be done:
- Clinicaltrials.gov: US and international registry for clinical trials, first of its kind, established 1997: https://clinicaltrials.gov/
>[![]({{ page.root }}/fig/01-ClinicalTrials.png){: height="50px"}](https://clinicaltrials.gov/)  
>
>- OSF: General purpose registry, also a research management tool (not just for preregistration), embargo possible for up to 4 years:
>https://osf.io/ 
>[![]({{ page.root }}/fig/01-OSF.png){: height="50px"}](https://osf.io/)
>
>- Aspredicted: General purpose registry, protocols can be private forever, possibility to automatically delete an entry after 24 hours:   
>https://aspredicted.org/
>[![]({{ page.root }}/fig/01-AsPredicted.png){: height="50px"}](https://aspredicted.org/)  
>
>- Preclinicaltirals.ed: Comprehensive listing of preclinical animal study protocols  
>https://preclinicaltrials.eu/
>[![]({{ page.root }}/fig/01-PreClinicalTrials.png){: height="50px"}](https://preclinicaltrials.eu/)  
>
>- PROSPERO International prospective register of systematic reviews  
>https://www.crd.york.ac.uk/prospero/
>[![]({{ page.root }}/fig/01-NIHR.png){: height="50px"}](https://www.crd.york.ac.uk/prospero/)  
>
{: .checklist}

## Quiz on registration 
>##  Does registration show an effect? 
>
All large National Heart Lung, and Blood Institute (NHLBI) supported randomized controlled trials between 1970 and 2012 evaluating drugs or dietary supplements for the treatment or prevention of cardiovascular disease are shown with their reported outcome measure in the graphic. Trials were included if direct costs were bigger than 500,000$/year, participants were adult humans, and the primary outcome was cardiovascular risk, disease or death. 
>
![]({{ page.root }}/fig/01-ExampleRegistration.png){: height="350px"}  
Image Credit: R Kaplan and V Irvin [https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0132382](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0132382), CC-BY.
>
> What is the difference between what you observe before and after the year 2000 in this graphic?
>
{: .challenge}

> ## Solution
> Before 2000 one sees many positive effects, i.e. treatments that lower the relative risk of cardiovascular disease, but also null effects, in general the effects are larger. After registration of the primary outcome becomes mandatory, less outcome switching can occur and many more null effects are reported. The policy change helped to overcome this particular aspect of selective reporting.
>
{: .solution}

&nbsp;

# 3. What is reproducibility?

>## Reproducibility vs replicability
>
>**Reproducibility** refers to the ability of a researcher to duplicate the results of a prior study using the same materials as were used by the original investigator.
> This requires, at minimum, the sharing of data sets, relevant metadata, analytical code, and related software.
>
**Replicability** refers to the ability of a researcher to duplicate the results of a prior study if the same procedures are followed but new data are collected.
>
See S Goodman et al. [https://www.science.org/doi/10.1126/scitranslmed.aaf5027](https://www.science.org/doi/10.1126/scitranslmed.aaf5027) for a finer grained discussion of the concepts.
>
{: .callout}

## What is reproducibility?
"This is exactly how it seems when you try to figure out how authors got from a large and complex data set to a dense paper with lots of busy figures. Without access to the data and the analysis code, a miracle occurred. And there should be no miracles in science."

See artwork by Sidney Harris at [http://www.sciencecartoonsplus.com/](http://www.sciencecartoonsplus.com/) for an illustration of the remark "I think you should be more explicit here in step two" when a miracle occurs.

The quote is from F Markowetz [https://genomebiology.biomedcentral.com/articles/10.1186/s13059-015-0850-7](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-015-0850-7). In this publication the author asks what working reproducibly means for his daily work and comes up with "Five selfish reasons to work reproducibly", this is even the title of the paper.

> _“Working transparently and reproducibly has a lot to do with empathy: put yourself into the shoes of one of your collaboration partners and ask yourself, would that person be able to access my data and make sense of my analyses. Learning the tools of the trade will require commitment and a massive investment of your time and energy. A priori it is not clear why the benefits of working reproducibly outweigh its costs.”_

In this course we will learn about some of the tools Markowetz lists in his paper.

## (Anti-)Example from the Markowetz paper
>## How bright promise in cancer testing fell apart
>
![]({{ page.root }}/fig/01-baggerlycoombes.png){: height="400px"}
Image Credit: adapted from the open access article by  K Baggerly and K Coombes [https://projecteuclid.org/journals/annals-of-applied-statistics/volume-3/issue-4/Deriving-chemosensitivity-from-cell-lines--Forensic-bioinformatics-and-reproducible/10.1214/09-AOAS291.full](https://projecteuclid.org/journals/annals-of-applied-statistics/volume-3/issue-4/Deriving-chemosensitivity-from-cell-lines--Forensic-bioinformatics-and-reproducible/10.1214/09-AOAS291.full).
>
From G  Kolata [https://www.nytimes.com/2011/07/08/health/research/08genes.html](https://www.nytimes.com/2011/07/08/health/research/08genes.html), picture by Michael Stravato for The New York Times.
>
>> _“When Juliet Jacobs found out she had lung cancer, she was terrified, but realized that her hope lay in getting the best treatment medicine could offer. So she got a second opinion, then a third. In February of 2010, she ended up at Duke University, where she entered a research study whose promise seemed stunning._
>
>> _Doctors would assess her tumor cells, looking for gene patterns that would determine which drugs would best attack her particular cancer. She would not waste precious time with ineffective drugs or trial-and-error treatment. The Duke program — considered a breakthrough at the time — was the first fruit of the new genomics, a way of letting a cancer cell’s own genes reveal the cancer’s weaknesses._
>
>> _But the research at Duke turned out to be wrong. Its gene-based tests proved worthless, and the research behind them was discredited. Ms. Jacobs died a few months after treatment, and her husband and other patients’ relatives have retained lawyers.”_ 
>
> Markowetz wonders in his paper why no one noticed these issues before it was too late. And he comes to the conclusion that the reason was that the data and analysis were not transparent and required forensic bioinformatics to untangle 
>
>Those forensic bioinformatics were provided by K Baggerly and K Coombes [https://projecteuclid.org/journals/annals-of-applied-statistics/volume-3/issue-4/Deriving-chemosensitivity-from-cell-lines--Forensic-bioinformatics-and-reproducible/10.1214/09-AOAS291.full](https://projecteuclid.org/journals/annals-of-applied-statistics/volume-3/issue-4/Deriving-chemosensitivity-from-cell-lines--Forensic-bioinformatics-and-reproducible/10.1214/09-AOAS291.full):
>
>> _“Poor documentation hid an off-by-one indexing error affecting all genes reported, the inclusion of genes from other sources, including other arrays (the outliers), and a sensitive/resistant label reversal.”_
>
>**Bottom line**: Data analyses that are done using reproducible code and that are documented well are easier to check, for the analysts themselves and for others. Such practices decrease the chances that errors as in this example are made and this outweighs the effort and time they cost.
{: .testimonial}

&nbsp;
&nbsp;


# Episode challenge

>## A waste of 1000 research papers
>
  Read the article "[A Waste of 1000 Research Papers](https://www.theatlantic.com/science/archive/2019/05/waste-1000-studies/589684/)" by Ed Yong (The Atlantic, 27.5. 2019). 
>
>>## Question 1
Find situations in the article where publication bias, preregistration and data sharing could have aided to avoid such waste. Copy the corresponding lines from the article and name one or two reasons why you think that those concepts could have helped. 
>{: .checklist}
>
>>## Question 2
Use smart search terms to find the concepts such that you do not need to read the entire research article.
>{: .checklist}
>
>>## Question 3
Go to the research article of [Border et al.](https://doi.org/10.1176/appi.ajp.2018.18070881) that is mentioned in Yong's article and find out which of the above concepts have been respected in this article. Justify with citations.
>{: .checklist}
>
>>## Question 4
What are your overall conclusions? 
>{: .checklist}
{: .challenge}


> ## Solution
> 
> No solution provided here.
>
{: .solution}


